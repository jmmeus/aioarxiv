from __future__ import annotations

from typing import List, Optional
import feedparser
import os
import re

import aiohttp
import logging

from aioarxiv.models.utilities import validate_arxiv_url

logger = logging.getLogger(__name__)


class BaseResult(object):
    """A base class for shared attributes and methods between SearchResult and RSSResult."""

    entry_id: str
    """A url of the form `https://arxiv.org/abs/{id}`."""
    title: str
    """The title of the result."""
    authors: List[Author]
    """The result's authors."""
    summary: str
    """The result abstract."""
    journal_ref: Optional[str]
    """A journal reference if present."""
    doi: Optional[str]
    """A URL for the resolved DOI to an external resource if present."""
    categories: List[str]
    """
    All of the result's categories. See [arXiv: Category
    Taxonomy](https://arxiv.org/category_taxonomy).
    """
    links: List[Link]
    """Up to three URLs associated with this result."""
    pdf_url: Optional[str]
    """The URL of a PDF version of this result if present among links."""
    _raw: feedparser.FeedParserDict
    """
    The raw feedparser result object if this BaseResult was constructed with
    BaseResult._from_feed_entry.
    """

    def __init__(
        self,
        entry_id: str,
        title: str = "",
        authors: List[Author] = [],
        summary: str = "",
        journal_ref: str = "",
        doi: str = "",
        categories: List[str] = [],
        links: List[Link] = [],
        _raw: feedparser.FeedParserDict = None,
    ):
        """
        Constructs an arXiv result item.
        """
        self.entry_id = entry_id
        self.title = title
        self.authors = authors
        self.summary = summary
        self.journal_ref = journal_ref
        self.doi = doi
        self.categories = categories
        self.links = links
        # Calculated members
        self.pdf_url = self._get_pdf_url(links, entry_id)
        # Debugging
        self._raw = _raw

    def __str__(self) -> str:
        return self.entry_id

    def __eq__(self, other) -> bool:
        if isinstance(other, BaseResult):
            return self.entry_id == other.entry_id
        return False

    def get_short_id(self) -> str:
        """
        Returns the short ID for this result.

        + If the result URL is `"https://arxiv.org/abs/2107.05580v1"`,
        `result.get_short_id()` returns `2107.05580v1`.

        + If the result URL is `"https://arxiv.org/abs/quant-ph/0201082v1"`,
        `result.get_short_id()` returns `"quant-ph/0201082v1"` (the pre-March
        2007 arXiv identifier format).

        For an explanation of the difference between arXiv's legacy and current
        identifiers, see [Understanding the arXiv
        identifier](https://arxiv.org/help/arxiv_identifier).
        """
        return self.entry_id.split("arxiv.org/abs/")[-1]

    def _get_default_filename(self, extension: str = "pdf") -> str:
        """
        A default `to_filename` function for the extension given.
        """
        nonempty_title = self.title if self.title else "UNTITLED"
        return ".".join(
            [
                self.get_short_id().replace("/", "_"),
                re.sub(r"[^\w]", "_", nonempty_title),
                extension,
            ]
        )

    async def download_pdf(
        self,
        dirpath: str = "./",
        filename: str = "",
        session: Optional[aiohttp.ClientSession] = None,
    ) -> str:
        """
        Downloads the PDF for this result to the specified directory.

        The filename is generated by calling `to_filename(self)`.
        """
        if not filename:
            filename = self._get_default_filename()
        path = os.path.join(dirpath, filename)
        os.makedirs(dirpath, exist_ok=True)

        # Create a session if not provided
        close_session = session is None
        session = session or aiohttp.ClientSession()

        try:
            async with session.get(self.pdf_url) as response:
                response.raise_for_status()
                with open(path, "wb") as f:
                    f.write(await response.read())
        finally:
            if close_session:
                await session.close()

        return path

    async def download_source(
        self,
        dirpath: str = "./",
        filename: str = "",
        session: Optional[aiohttp.ClientSession] = None,
    ) -> str:
        """
        Downloads the source tarfile for this result to the specified
        directory.

        The filename is generated by calling `to_filename(self)`.
        """
        if not filename:
            filename = self._get_default_filename("tar.gz")
        path = os.path.join(dirpath, filename)
        os.makedirs(dirpath, exist_ok=True)

        # Bodge: construct the source URL from the PDF URL.
        source_url = self.pdf_url.replace("/pdf/", "/src/")

        # Create a session if not provided
        close_session = session is None
        session = session or aiohttp.ClientSession()

        try:
            async with session.get(source_url) as response:
                response.raise_for_status()
                with open(path, "wb") as f:
                    f.write(await response.read())
        finally:
            if close_session:
                await session.close()

        return path

    @staticmethod
    def _get_pdf_url(links: List[Link], entry_id: str) -> Optional[str]:
        """
        Finds the PDF link among a result's links and returns its URL.

        Should only be called once for a given `BaseResult`, in its constructor.
        After construction, the URL should be available in `BaseResult.pdf_url`.
        """
        pdf_urls = [link.href for link in links if link.title == "pdf"]
        if len(pdf_urls) == 0:
            logger.warning(
                "Result %s has no PDF link, constructing possible pdf link from entry_id", entry_id
            )

            if validate_arxiv_url(entry_id):
                asd_urls = [entry_id]
            else:
                asd_urls = [link.href for link in links if validate_arxiv_url(link.href)]
            if len(asd_urls) == 0:
                return None
            elif len(asd_urls) > 1:
                logger.warning(
                    "Result %s has multiple ADS links; using %s for pdf link construction",
                    entry_id,
                    asd_urls[0],
                )
            return re.sub(r"/abs/", "/pdf/", asd_urls[0], count=1)
        elif len(pdf_urls) > 1:
            logger.warning("Result %s has multiple PDF links; using %s", entry_id, pdf_urls[0])
        return pdf_urls[0]

    class Author(object):
        """
        A light inner class for representing a result's authors.
        """

        name: str
        """The author's name."""
        institutions: Optional[str]
        """The author's institutions if available."""

        def __init__(self, name: str, institutions: Optional[str] = None):
            """
            Constructs an `Author` with the specified name.

            In most cases, prefer using `Author._from_feed_author` to parsing
            and constructing `Author`s yourself.
            """
            self.name = name
            self.institutions = institutions

        @classmethod
        def _from_feed_author(cls, feed_author: feedparser.FeedParserDict) -> BaseResult.Author:
            """
            Constructs an `Author` with the name specified in an author object
            from a feed entry.

            See usage in `BaseResult._from_feed_entry`.
            """
            return cls(feed_author.name)

        def __str__(self) -> str:
            return self.name

        def __repr__(self):
            return (
                f"{self.__class__.__name__}(name={self.name!r}, institutions={self.institutions!r})"
            )

        def __eq__(self, other) -> bool:
            if isinstance(other, BaseResult.Author):
                return self.name == other.name
            return False

    class Link(object):
        """
        A light inner class for representing a result's links.
        """

        href: str
        """The link's `href` attribute."""
        title: Optional[str]
        """The link's title."""
        rel: Optional[str]
        """The link's relationship to the `BaseResult`."""
        content_type: Optional[str]
        """The link's HTTP content type."""

        def __init__(
            self,
            href: str,
            title: Optional[str] = None,
            rel: Optional[str] = None,
            content_type: Optional[str] = None,
        ):
            """
            Constructs a `Link` with the specified link metadata.

            In most cases, prefer using `Link._from_feed_link` to parsing and
            constructing `Link`s yourself.
            """
            self.href = href
            self.title = title
            self.rel = rel
            self.content_type = content_type

        @classmethod
        def _from_feed_link(cls, feed_link: feedparser.FeedParserDict) -> BaseResult.Link:
            """
            Constructs a `Link` with link metadata specified in a link object
            from a feed entry.

            See usage in `BaseResult._from_feed_entry`.
            """
            return cls(
                href=feed_link.href,
                title=feed_link.get("title"),
                rel=feed_link.get("rel"),
                content_type=feed_link.get("content_type"),
            )

        def __str__(self) -> str:
            return self.href

        def __repr__(self) -> str:
            return (
                f"{self.__class__.__name__}({repr(self.href)}, "
                f"title={repr(self.title)}, "
                f"rel={repr(self.rel)}, "
                f"content_type={repr(self.content_type)})"
            )

        def __eq__(self, other) -> bool:
            if isinstance(other, BaseResult.Link):
                return self.href == other.href
            return False

    class MissingFieldError(Exception):
        """
        An error indicating an entry is unparseable because it lacks required
        fields.
        """

        missing_field: str
        """The required field missing from the would-be entry."""
        message: str
        """Message describing what caused this error."""

        def __init__(self, missing_field: str):
            self.missing_field = missing_field
            self.message = "Entry from arXiv missing required info"

        def __repr__(self) -> str:
            return f"{self.__class__.__name__}({repr(self.missing_field)})"


class BaseQuery(object):
    """
    A base object for a query of arXiv's database.

    To run a query, use `Client.results` with an instantiated client.
    """

    query: str
    """
    A query string.

    This should be unencoded. Use `au:del_maestro AND ti:checkerboard`, not
    `au:del_maestro+AND+ti:checkerboard`.

    See [the arXiv API User's Manual: Details of Query
    Construction](https://arxiv.org/help/api/user-manual#query_details) for Search
    queries.

    see [the arXiv RSS news feeds](https://info.arxiv.org/help/rss.html) for RSS
    queries.
    """
    max_results: Optional[int]
    """
    The maximum number of results to be returned in an execution of this
    query. To fetch every result available, set `max_results=None`.

    The API's limit is 300,000 results per query for Searches, and 2,000 for RSS feeds.
    """
    id_list: List[str]
    """
    A list of arXiv article IDs to which to limit the search.

    See [the arXiv API User's
    Manual](https://arxiv.org/help/api/user-manual#search_query_and_id_list)
    for documentation of the interaction between `query` and `id_list`.
    """

    def __init__(
        self,
        query: str = "",
        max_results: Optional[int] = None,
        id_list: List[str] = [],
    ):
        """
        Constructs an arXiv API query with the specified criteria.
        """
        self.query = query
        self.max_results = max_results
        self.id_list = id_list

    def __str__(self) -> str:
        # TODO: develop a more informative string representation.
        return repr(self)
